# -*- coding: utf-8 -*-
"""FFA_Net_46x62_Trained_Scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IdkbrMRq36XHrh8VOYrVumi8yr8xPt6I
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cp -R '/content/drive/MyDrive/CVPROJECT/CV_Project/Dataset' './'

!ls Dataset

# Commented out IPython magic to ensure Python compatibility.
# %cd Dataset

!unzip archive.zip

!ls

# Commented out IPython magic to ensure Python compatibility.
# %pip install torch

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision
import numpy as np
import cv2

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# from PIL import Image 
# from torchvision import transforms
# # im = transforms.ToPILImage()(t).convert("RGB")
# class SOTS(Dataset):
#   def __init__(self):
#     # self.pathx='/content/drive/MyDrive/Dataset/SOTS/SOTS/indoor/hazy' # Nikhila
#     # self.pathy='/content/drive/MyDrive/Dataset/SOTS/SOTS/indoor/gt' #Nikhila
    
#     # self.pathx='/content/drive/MyDrive/CVPROJECT/CV_Project/Dataset/SOTS/SOTS/indoor/hazy' #Adhun
#     # self.pathy='/content/drive/MyDrive/CVPROJECT/CV_Project/Dataset/SOTS/SOTS/indoor/gt' #Adhun
#     self.pathx='hazy' #Adhun
#     self.pathy='clear' #Adhun
#     self.x=sorted(os.listdir(self.pathx))
#     self.y=sorted(os.listdir(self.pathy))
#     self.new=[]
#     for i in self.x:
#       self.new.append(i.split('_')[0])
#     self.xi=np.argsort(np.array(self.new))
#     self.sorted_x=[]
#     for i in self.xi:
#       # print(i)
#       self.sorted_x.append(self.x[i])
#     self.newy=[]
#     for i in self.y:
#       self.newy.append(i.split('.')[0])
#     self.yi=np.argsort(np.array(self.newy))

#     self.sorted_y=[]
#     for i in self.yi:
#       self.sorted_y.append(self.y[i])
#     # self.ydir=os.listdir(self.pathy)
#     # for file in os.listdir(self.pathx):
#     #     img = Image.open(os.path.join(self.pathx,file))
#     #     x = transforms.ToTensor()(img)
#     #     x = x[:3]
#     #     self.x.append(x)
#     self.x=self.sorted_x
#     self.y=[]
#     for file in self.sorted_y:
#       for i in range(10):
#         self.y.append(file)
#     #     x = transforms.ToTensor()(img)
#     #     x = x[:3]
#     #     self.y.append(x)
#     # self.x=np.array(self.x)
#     # self.y=np.array(self.y)
#   def __getitem__(self,index):
#         x = Image.open(os.path.join(self.pathx,self.x[index]))
#         x = x.resize((62, 46))
#         x = transforms.ToTensor()(x)
#         x = x[:3]
#         y = Image.open(os.path.join(self.pathy,self.y[index]))
#         y = y.resize((62, 46))
#         y = transforms.ToTensor()(y)
#         y = y[:3]
#         return x,y
#   def __len__(self):
#     return len(self.x)

import glob

class RESIDEDataset(Dataset):
    def __init__(self, path, train = True, transform=None):
        self.path = path
        self.transform = transform
        self.train = train
        # print(self.path+'hazy/')
        if self.train:
          self.images_hazy = sorted([file for file in glob.glob(self.path + 'hazy/' + '*')])
          self.images_clear = sorted([file for file in glob.glob(self.path + 'clear/' + '*')])
          self.clear_base_path = self.path + 'clear/'
          # print(self.images_clear )
        else:
          self.images_hazy = sorted([file for file in glob.glob(self.path + 'hazy/' + '*')])
          self.images_clear = sorted([file for file in glob.glob(self.path + 'gt/' + '*')])
          self.clear_base_path = self.path + 'gt/'

            
    def __getitem__(self,index):
        # print(self.images_hazy)
        image_hazy_path = self.images_hazy[index]
        #hazy = Image.open(image_hazy_path)
        hazy = cv2.imread(image_hazy_path)
        hazy = cv2.cvtColor(hazy, cv2.COLOR_BGR2RGB)

        # print(image_hazy_path)
        clear_hazy_path = self.clear_base_path + image_hazy_path.split('/')[-1].split('_')[0] + '.png'
        #print(clear_hazy_path)
        #clear = Image.open(clear_hazy_path)
        clear = cv2.imread(clear_hazy_path)
        clear = cv2.cvtColor(clear, cv2.COLOR_BGR2RGB)


        if self.transform:
            transformed = self.transform(image=hazy, mask=clear)
            hazy_transformed = transformed['image']
            clear_transformed = torch.squeeze(transformed['mask']).permute(2,0,1)

        return hazy_transformed, clear_transformed
        
    def __len__(self):
        return len(self.images_hazy)

import albumentations as A
from albumentations.pytorch import ToTensor

train_transform = A.Compose(
    [
        A.CenterCrop(height=224, width=224),
        A.Resize( 46,62),
        #A.RandomCrop(height=128, width=128),
        A.HorizontalFlip(),
        A.Rotate(30),
        #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensor(),
    ])

test_transform = A.Compose(
    [
        A.CenterCrop(height=224, width=224),
        A.Resize( 46,62),
        ToTensor(),
    ])



import os
# dataset = SOTS()
dataset = RESIDEDataset(path = '/content/Dataset/', train = True, transform = train_transform)
# testset = RESIDEDataset(path = '/content/Dataset', train = False, transform = train_transform)
first_data= dataset[1]

# print(dataset[49])

print(len(dataset))
# print(dataset[len(dataset)])
# first_data= dataset[500]
features, label= first_data
print(features.shape)
print(label.shape)
# print(label)
# print(type(first_data))

print(dataset)
BATCHSIZE=64
trainloader = DataLoader(dataset=dataset, batch_size=BATCHSIZE, num_workers=2, shuffle=True)
print(trainloader)
# dataiter=iter(trainloader)
# data=dataiter.next()
# print(data)
# features,j= data
# print(j[0])

import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


def imshow(img):
    # img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))
imshow(torchvision.utils.make_grid(labels))
# print labels

import torch.nn as nn
import torch

def default_conv(in_channels, out_channels, kernel_size, bias=True):
    # print('defconv')

    return nn.Conv2d(in_channels, out_channels, kernel_size,padding=(kernel_size//2), bias=bias)
    
class PALayer(nn.Module):
    def __init__(self, channel):
        super(PALayer, self).__init__()
        self.pa = nn.Sequential(
                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),
                nn.ReLU(inplace=True),
                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),
                nn.Sigmoid()
        )
    def forward(self, x):
        # print('forward PALAyer')

        y = self.pa(x)
        return x * y

class CALayer(nn.Module):
    def __init__(self, channel):
        super(CALayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.ca = nn.Sequential(
                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),
                nn.ReLU(inplace=True),
                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),
                nn.Sigmoid()
        )

    def forward(self, x):
        # print('forward CALayer')

        y = self.avg_pool(x)
        y = self.ca(y)
        return x * y

class Block(nn.Module):
    def __init__(self, conv, dim, kernel_size,):
        super(Block, self).__init__()
        self.conv1=conv(dim, dim, kernel_size, bias=True)
        self.act1=nn.ReLU(inplace=True)
        self.conv2=conv(dim,dim,kernel_size,bias=True)
        self.calayer=CALayer(dim)
        self.palayer=PALayer(dim)
    def forward(self, x):
        # print('forward block')

        res=self.act1(self.conv1(x))
        res=res+x 
        res=self.conv2(res)
        res=self.calayer(res)
        res=self.palayer(res)
        res += x 
        return res
class Group(nn.Module):
    def __init__(self, conv, dim, kernel_size, blocks):
        super(Group, self).__init__()
        modules = [ Block(conv, dim, kernel_size)  for _ in range(blocks)]
        modules.append(conv(dim, dim, kernel_size))
        self.gp = nn.Sequential(*modules)
    def forward(self, x):
        # print('forward Group')

        res = self.gp(x)
        res += x
        return res

class FFA(nn.Module):
    def __init__(self,gps=3,blocks=19,conv=default_conv):

        super(FFA, self).__init__()
        self.gps=gps
        self.dim=64
        kernel_size=3
        pre_process = [conv(3, self.dim, kernel_size)]
        assert self.gps==3
        self.g1= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.g2= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.g3= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.ca=nn.Sequential(*[
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),
            nn.Sigmoid()
            ])
        self.palayer=PALayer(self.dim)

        post_precess = [
            conv(self.dim, self.dim, kernel_size),
            conv(self.dim, 3, kernel_size)]

        self.pre = nn.Sequential(*pre_process)
        self.post = nn.Sequential(*post_precess)

    def forward(self, x1):
        # print('forward')
        x = self.pre(x1)
        res1=self.g1(x)
        res2=self.g2(res1)
        res3=self.g3(res2)
        w=self.ca(torch.cat([res1,res2,res3],dim=1))
        w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]
        out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3
        out=self.palayer(out)
        x=self.post(out)

        return x + x1

net=FFA(gps=3,blocks=19).to(device)

!pip install kornia

from kornia.losses import ssim, psnr, ssim_loss, psnr_loss

import math
epochs=15
totalsamples=len(dataset)
iterations= math.ceil(totalsamples/BATCHSIZE)
stepsize=10
from torch import optim
# from option import opt,model_name,log_dir

criterion = nn.L1Loss().to(device)
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
running_loss = 0.0
ssim_total=0
psnr_total=0
samples_num=0
psnr_score_running=0
ssim_score_running=0
run=0
for epoch in range(epochs):
  for i,(inputs,groundtruth) in enumerate(trainloader):
    run+=1
    net.train()
    inputs = inputs.to(device)
    
    groundtruth = groundtruth.to(device)
    net = net.to(device)
    out=net(inputs)
    out=out.to(device)
    loss=criterion(out,groundtruth)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    ssim_score = torch.mean(ssim(groundtruth, out, 5))
    psnr_score = psnr(groundtruth, out, 1)

    ssim_score_running += ssim_score.detach().cpu().item()
    psnr_score_running += psnr_score.detach().cpu().item()

    running_loss+=loss.item()
    if (i+1)%stepsize==0 or i+1==iterations:
      print(f'epoch {epoch+1}/{epochs} | step {(i+1)}/{iterations}  | running loss { running_loss /run} | ssim {ssim_score_running/run} | psnr {psnr_score_running/run}')
      running_loss = 0.0
      ssim_score_running = 0
      psnr_score_running = 0
      run=0
print('Finished Training')

path='/content/drive/MyDrive/CVPROJECT/CV_Project/FFANet_org/FFA-Net-master/Models/Model_62_46_15epoch.pth'

torch.save(net,path )

import torch

model=torch.load(path)
model.eval()

dataiter = iter(trainloader)
images, labels = dataiter.next()
import matplotlib.pyplot as plt

out=model(images.to(device))

def imshow(img):
    img = img      # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# show images
imshow(torchvision.utils.make_grid(images))
imshow(torchvision.utils.make_grid(labels))
#out = model(images)
imshow(torchvision.utils.make_grid(out.cpu()))

!ls

!unzip SOTS.zip



testset_its = RESIDEDataset(path = '/content/Dataset/SOTS/SOTS/indoor/', train = False, transform = test_transform)
testset_ots = RESIDEDataset(path = '/content/Dataset/SOTS/SOTS/outdoor/', train = False, transform = test_transform)

batchsize=64

testloader_its = torch.utils.data.DataLoader(testset_its, batch_size=batchsize, shuffle=False, num_workers=2)

testloader_ots = torch.utils.data.DataLoader(testset_ots, batch_size=batchsize, shuffle=False, num_workers=2)

def test_epoch(model, testloader, phase='test'):
    model.eval()

    epoch_loss = 0.
    #epoch_acc = 0.
    
    batch_num = 0.
    samples_num = 0.
    psnr_score_running = 0.
    ssim_score_running = 0.
    
    #true_labels = []
    #pred_labels = []

    with torch.no_grad():
      for batch_idx, data in  enumerate(testloader):

        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        model = model.to(device)
        pred_masks = model(inputs)
        #loss_fn_alex = lpips.LPIPS(net='alex', verbose = False).cuda()  ### AlexNet perpetual loss
        #loss_dist = loss_fn_alex(labels, pred_masks)
        #ssim_loss_batch = ssim_loss(labels, pred_masks, 5) ## Include in composite loss
        #psnr_loss_batch = psnr_loss(labels, pred_masks, 1) ## Include in composite loss
        #loss = torch.mean(loss_dist)

        ####print(f'\r{phase} batch [{batch_idx}/{len(testloader)}]: loss {torch.mean(loss).item()}', end='', flush=True)
        #epoch_loss += torch.mean(loss.detach().cpu()).item()

        ssim_score = torch.mean(ssim(labels, pred_masks, 11))
        #print(ssim_score)
        psnr_score = psnr(labels, pred_masks, 1)
  
        ssim_score_running += ssim_score.detach().cpu().item()*len(labels)
        psnr_score_running += psnr_score.detach().cpu().item()*len(labels)
        
        batch_num += 1
        samples_num += len(labels)
      return epoch_loss / batch_num, ssim_score_running / samples_num, psnr_score_running/ samples_num

dataiter = iter(testloader_ots)
images, labels = dataiter.next()
import matplotlib.pyplot as plt

out=model(images.to(device))

def imshow(img):
    img = img      # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# show images
imshow(torchvision.utils.make_grid(images))
imshow(torchvision.utils.make_grid(labels))
#out = model(images)
imshow(torchvision.utils.make_grid(out.cpu()))

epochs = 1

for epoch in range(epochs):

    print('='*15, f'Epoch: {epoch}')
    
    test_loss, test_ssim, test_psnr = test_epoch(model, testloader_its, phase='test') 

    print()
    print(f'Test SSIM: {test_ssim}, Test PSNR: {test_psnr}')
    print()

epochs = 1

for epoch in range(epochs):

    print('='*15, f'Epoch: {epoch}')
    
    test_loss, test_ssim, test_psnr = test_epoch(model, testloader_ots, phase='test') 

    print()
    print(f'Test SSIM: {test_ssim}, Test PSNR: {test_psnr}')
    print()

