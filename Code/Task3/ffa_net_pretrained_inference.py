# -*- coding: utf-8 -*-
"""FFA_Net_Pretrained_Inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rcB02vbzPw_raQl7rH6d6aaIXTVMKV66
"""

!nvidia-smi

!pip install kornia

# Import necessary libraries

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split, SubsetRandomSampler
from torchvision.datasets import CIFAR10
from torchvision import datasets, transforms
from torch.optim import *

import os
import random
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
import cv2
import glob
import copy

from sklearn.model_selection import train_test_split
#import wandb

from torchsummary import summary

from skimage.feature import hog
from tqdm import tqdm as tqdm

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

seed = 42

from numba import jit, cuda

import torch
import numpy as np
from torch.utils.data import TensorDataset, DataLoader, Dataset

from PIL import Image
import glob

import albumentations as A
from albumentations.pytorch import ToTensor

# https://kornia.readthedocs.io/en/latest/losses.html
from kornia.losses import ssim, psnr, ssim_loss, psnr_loss



# Mount google drive to colab

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#!git clone https://github.com/zhilin007/FFA-Net.git



!mkdir FFA_trained_models
!cp -r /content/drive/MyDrive/CV_Project/FFA_trained_models/its_train_ffa_3_19.pk /content/FFA_trained_models/
!cp -r /content/drive/MyDrive/CV_Project/FFA_trained_models/ots_train_ffa_3_19.pk /content/FFA_trained_models/

!ls -lrt /content/FFA_trained_models/



!cp /content/drive/MyDrive/CV_Project/Dataset/SOTS.zip ./

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!unzip -qq SOTS.zip

!ls -lrt ./SOTS/

!ls -lrt /content/SOTS/outdoor/

!rm -rf /content/SOTS/outdoor/hazy/0051_0.95_0.12.jpg
!rm -rf /content/SOTS/outdoor/hazy/0076_1_0.16.jpg
!rm -rf /content/SOTS/outdoor/hazy/0086_0.95_0.12.jpg
!rm -rf /content/SOTS/outdoor/hazy/0108_1_0.2.jpg
!rm -rf /content/SOTS/outdoor/hazy/0253_1_0.16.jpg
!rm -rf /content/SOTS/outdoor/hazy/0287_0.95_0.08.jpg
!rm -rf /content/SOTS/outdoor/hazy/0330_0.8_0.08.jpg
!rm -rf /content/SOTS/outdoor/hazy/0320_0.9_0.08.jpg

!ls -lrt





import torch.nn as nn
import torch

def default_conv(in_channels, out_channels, kernel_size, bias=True):
    return nn.Conv2d(in_channels, out_channels, kernel_size,padding=(kernel_size//2), bias=bias)
    
class PALayer(nn.Module):
    def __init__(self, channel):
        super(PALayer, self).__init__()
        self.pa = nn.Sequential(
                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),
                nn.ReLU(inplace=True),
                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),
                nn.Sigmoid()
        )
    def forward(self, x):
        y = self.pa(x)
        return x * y

class CALayer(nn.Module):
    def __init__(self, channel):
        super(CALayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.ca = nn.Sequential(
                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),
                nn.ReLU(inplace=True),
                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),
                nn.Sigmoid()
        )

    def forward(self, x):
        y = self.avg_pool(x)
        y = self.ca(y)
        return x * y

class Block(nn.Module):
    def __init__(self, conv, dim, kernel_size,):
        super(Block, self).__init__()
        self.conv1=conv(dim, dim, kernel_size, bias=True)
        self.act1=nn.ReLU(inplace=True)
        self.conv2=conv(dim,dim,kernel_size,bias=True)
        self.calayer=CALayer(dim)
        self.palayer=PALayer(dim)
    def forward(self, x):
        res=self.act1(self.conv1(x))
        res=res+x 
        res=self.conv2(res)
        res=self.calayer(res)
        res=self.palayer(res)
        res += x 
        return res
class Group(nn.Module):
    def __init__(self, conv, dim, kernel_size, blocks):
        super(Group, self).__init__()
        modules = [ Block(conv, dim, kernel_size)  for _ in range(blocks)]
        modules.append(conv(dim, dim, kernel_size))
        self.gp = nn.Sequential(*modules)
    def forward(self, x):
        res = self.gp(x)
        res += x
        return res

class FFA(nn.Module):
    def __init__(self,gps,blocks,conv=default_conv):
        super(FFA, self).__init__()
        self.gps=gps
        self.dim=64
        kernel_size=3
        pre_process = [conv(3, self.dim, kernel_size)]
        assert self.gps==3
        self.g1= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.g2= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.g3= Group(conv, self.dim, kernel_size,blocks=blocks)
        self.ca=nn.Sequential(*[
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),
            nn.Sigmoid()
            ])
        self.palayer=PALayer(self.dim)

        post_precess = [
            conv(self.dim, self.dim, kernel_size),
            conv(self.dim, 3, kernel_size)]

        self.pre = nn.Sequential(*pre_process)
        self.post = nn.Sequential(*post_precess)

    def forward(self, x1):
        x = self.pre(x1)
        res1=self.g1(x)
        res2=self.g2(res1)
        res3=self.g3(res2)
        w=self.ca(torch.cat([res1,res2,res3],dim=1))
        w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]
        out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3
        out=self.palayer(out)
        x=self.post(out)
        return x + x1



model_dir_its = '/content/FFA_trained_models/its_train_ffa_3_19.pk'
model_dir_ots = '/content/FFA_trained_models/ots_train_ffa_3_19.pk'
device='cuda' if torch.cuda.is_available() else 'cpu'

gps=3
blocks=19
ckp_its=torch.load(model_dir_its,map_location=device)
net_its=FFA(gps=gps,blocks=blocks)
net_its=nn.DataParallel(net_its)
net_its.load_state_dict(ckp_its['model'])

gps=3
blocks=19
ckp_ots=torch.load(model_dir_ots,map_location=device)
net_ots=FFA(gps=gps,blocks=blocks)
net_ots=nn.DataParallel(net_ots)
net_ots.load_state_dict(ckp_ots['model'])



class RESIDEDataset(Dataset):
    def __init__(self, path, train = True, transform=None):
        self.path = path
        self.transform = transform
        self.train = train
        if self.train:
          self.images_hazy = sorted([file for file in glob.glob(self.path + 'hazy/' + '*')])
          self.images_clear = sorted([file for file in glob.glob(self.path + 'clear/' + '*')])
          self.clear_base_path = self.path + 'clear/'
        else:
          self.images_hazy = sorted([file for file in glob.glob(self.path + 'hazy/' + '*')])
          self.images_clear = sorted([file for file in glob.glob(self.path + 'gt/' + '*')])
          self.clear_base_path = self.path + 'gt/'

            
    def __getitem__(self,index):
        image_hazy_path = self.images_hazy[index]
        #hazy = Image.open(image_hazy_path)
        hazy = cv2.imread(image_hazy_path)
        hazy = cv2.cvtColor(hazy, cv2.COLOR_BGR2RGB)

        #print(image_hazy_path)
        clear_hazy_path = self.clear_base_path + image_hazy_path.split('/')[-1].split('_')[0] + '.png'
        #print(clear_hazy_path)
        #clear = Image.open(clear_hazy_path)
        clear = cv2.imread(clear_hazy_path)
        clear = cv2.cvtColor(clear, cv2.COLOR_BGR2RGB)


        if self.transform:
            transformed = self.transform(image=hazy, mask=clear)
            hazy_transformed = transformed['image']
            clear_transformed = torch.squeeze(transformed['mask']).permute(2,0,1)

        return hazy_transformed, clear_transformed
        
    def __len__(self):
        return len(self.images_hazy)



batch_size = 64

test_transform = A.Compose(
    [
        #A.CenterCrop(height=224, width=224),
        A.Resize(height=128, width=128),
        A.Normalize(mean=(0.64, 0.6, 0.58),std=(0.14,0.15, 0.152)),
        ToTensor(),
    ])


test_transform_display = A.Compose(
    [
        #A.CenterCrop(height=224, width=224),
        A.Resize(height=128, width=128),
        #A.Normalize(mean=(0.64, 0.6, 0.58),std=(0.14,0.15, 0.152)),
        ToTensor(),
    ])

testset_its = RESIDEDataset(path = '/content/SOTS/indoor/', train = False, transform = test_transform)
testset_ots = RESIDEDataset(path = '/content/SOTS/outdoor/', train = False, transform = test_transform)

testset_its_display = RESIDEDataset(path = '/content/SOTS/indoor/', train = False, transform = test_transform_display)
testset_ots_display = RESIDEDataset(path = '/content/SOTS/outdoor/', train = False, transform = test_transform_display)

testloader_its = torch.utils.data.DataLoader(testset_its, batch_size=batch_size, shuffle=False, num_workers=2)
testloader_ots = torch.utils.data.DataLoader(testset_ots, batch_size=batch_size, shuffle=False, num_workers=2)

testloader_its_display = torch.utils.data.DataLoader(testset_its_display, batch_size=batch_size, shuffle=False, num_workers=2)
testloader_ots_display = torch.utils.data.DataLoader(testset_ots_display, batch_size=batch_size, shuffle=False, num_workers=2)

"""### Indoor"""

dataiter = iter(testloader_its_display)
images_id, masks_id = dataiter.next()

print(type(images_id))
print(type(masks_id))
print(images_id.shape)
print(masks_id.shape)

# Display 5 Hazy Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(images_id[index*10].numpy().transpose(1, 2, 0))
plt.suptitle('Indoor Hazy Images', fontsize=90)
plt.subplots_adjust(top=0.95)



# Display 5 corresponding Clear Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(masks_id[index*10].numpy().transpose(1, 2, 0))
plt.suptitle('Indoor Clear Images', fontsize=90)
plt.subplots_adjust(top=0.95)





"""### Outdoor"""





dataiter = iter(testloader_ots_display)
images_od, masks_od = dataiter.next()

print(type(images_od))
print(type(masks_od))
print(images_od.shape)
print(masks_od.shape)



# Display 5 Hazy Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(images_od[index].numpy().transpose(1, 2, 0))
plt.suptitle('Outdoor Hazy Images', fontsize=90)
plt.subplots_adjust(top=0.95)



# Display 5 corresponding Clear Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(masks_od[index].numpy().transpose(1, 2, 0))
plt.suptitle('Outdoor Clear Images', fontsize=90)
plt.subplots_adjust(top=0.95)



def test_epoch(model, testloader, phase='test'):
    model.eval()

    epoch_loss = 0.
    #epoch_acc = 0.
    
    batch_num = 0.
    samples_num = 0.
    psnr_score_running = 0.
    ssim_score_running = 0.
    
    #true_labels = []
    pred_labels = []

    with torch.no_grad():
      for batch_idx, data in  enumerate(testloader):

        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        model = model.to(device)
        pred_masks = model(inputs)
        #loss_fn_alex = lpips.LPIPS(net='alex', verbose = False).cuda()  ### AlexNet perpetual loss
        #loss_dist = loss_fn_alex(labels, pred_masks)
        #ssim_loss_batch = ssim_loss(labels, pred_masks, 5) ## Include in composite loss
        #psnr_loss_batch = psnr_loss(labels, pred_masks, 1) ## Include in composite loss
        #loss = torch.mean(loss_dist)

        ####print(f'\r{phase} batch [{batch_idx}/{len(testloader)}]: loss {torch.mean(loss).item()}', end='', flush=True)
        #epoch_loss += torch.mean(loss.detach().cpu()).item()

        ssim_score = torch.mean(ssim(labels, pred_masks, 11))
        #print(ssim_score)
        psnr_score = psnr(labels, pred_masks, 1)
  
        ssim_score_running += ssim_score.detach().cpu().item()*len(labels)
        psnr_score_running += psnr_score.detach().cpu().item()*len(labels)
        
        batch_num += 1
        samples_num += len(labels)
      return epoch_loss / batch_num, ssim_score_running / samples_num, psnr_score_running/ samples_num



"""### SOTS Indoor - Inference (128x128 Resized)"""



test_loss, test_ssim, test_psnr = test_epoch(net_its, testloader_its, phase='test') 

print()
print(f'Test SSIM: {test_ssim}, Test PSNR: {test_psnr}')
print()







"""### SOTS Indoor - Dehazed FFA Net"""

dataiter = iter(testloader_its)
images_fid, masks_fid = dataiter.next()

print(type(images_fid))
print(type(masks_fid))
print(images_fid.shape)
print(masks_fid.shape)

net_its.eval()

with torch.no_grad():
  images_fid = images_fid.to(device)
  net_its = net_its.to(device)
  pred_masks_fid = net_its(images_fid)

# Display 5 corresponding Dehazed Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(pred_masks_fid[index*10].cpu().numpy().transpose(1, 2, 0))
plt.suptitle('Indoor Dehazed Images', fontsize=90)
plt.subplots_adjust(top=0.95)





"""### SOTS Outdoor - Inference (128x128 Resized)"""



test_loss, test_ssim, test_psnr = test_epoch(net_ots, testloader_ots, phase='test') 

print()
print(f'Test SSIM: {test_ssim}, Test PSNR: {test_psnr}')
print()







"""### SOTS Outdoor - Dehazed FFA Net"""

dataiter = iter(testloader_ots)
images_fod, masks_fod = dataiter.next()

print(type(images_fod))
print(type(masks_fod))
print(images_fod.shape)
print(masks_fod.shape)

net_ots.eval()

with torch.no_grad():
  images_fod = images_fod.to(device)
  net_ots = net_ots.to(device)
  pred_masks_fod = net_ots(images_fod)

# Display 5 corresponding Dehazed Images

figure = plt.figure()
num_of_images = 5
plt.figure(figsize=(100,50))
for index in range(0, num_of_images):
    plt.subplot(2, 5, index+1)
    plt.axis('off')
    plt.imshow(pred_masks_fod[index].cpu().numpy().transpose(1, 2, 0))
plt.suptitle('Outdoor Dehazed Images', fontsize=90)
plt.subplots_adjust(top=0.95)



