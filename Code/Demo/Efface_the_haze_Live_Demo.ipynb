{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Efface the haze_Live_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcm562za3NOh",
        "outputId": "feac8908-7cac-4d33-e84a-06c1c7d081e5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 13 07:42:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ3_RecjCmtU",
        "outputId": "ef82292b-eb13-4036-e8ae-59444cbd8d74"
      },
      "source": [
        "!pip install -q git+https://github.com/ChristophReich1996/Involution\n",
        "!pip install -q gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for involution (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 15.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 49.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 50.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 962kB 48.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDAJsLVBsfzq"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import *\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import cv2\n",
        "import glob\n",
        "import copy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import wandb\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from skimage.feature import hog\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "seed = 42\n",
        "\n",
        "from numba import jit, cuda\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "\n",
        "import torch\n",
        "from involution import Involution2d\n",
        "\n",
        "#involution = Involution2d(in_channels=32, out_channels=64)\n",
        "#output = involution(torch.rand(1, 32, 128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2nt-S6asf19",
        "outputId": "2bac1180-bbc0-48f5-ed2f-469e1ffbabb9"
      },
      "source": [
        "# Mount google drive to colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2RujjyP-rie"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJxPAsIYhb_E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l51lag2hcBt"
      },
      "source": [
        "class Block_en(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding = 1)\n",
        "        self.inonv1 = Involution2d(in_channels=in_ch, out_channels=out_ch, kernel_size = (3,3), padding = (1,1))\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding = 1)\n",
        "        self.inonv2 = Involution2d(in_channels=out_ch, out_channels=out_ch, kernel_size = (3,3), padding = (1,1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #return self.relu(self.conv2(self.relu(self.conv1(x))))\n",
        "        #print(self.inonv1(x).shape)\n",
        "        return self.relu(self.conv2(self.relu(self.inonv1(x))))\n",
        "        #return self.relu(self.inonv2(self.relu(self.inonv1(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raQ1rqqNDChq"
      },
      "source": [
        "class Block_de(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding = 1)\n",
        "        #self.inonv1 = Involution2d(in_channels=in_ch, out_channels=out_ch, kernel_size = (3,3), padding = (1,1))\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding = 1)\n",
        "        #self.inonv2 = Involution2d(in_channels=out_ch, out_channels=out_ch, kernel_size = (3,3), padding = (1,1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv2(self.relu(self.conv1(x))))\n",
        "        #print(self.inonv1(x).shape)\n",
        "        #return self.relu(self.conv2(self.relu(self.inonv1(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JprSDDHwJYg"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, chs=(3,64,128,256,512,1024)):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([Block_en(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ftrs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            ftrs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpBaY6WUwL5y"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
        "        super().__init__()\n",
        "        self.chs         = chs\n",
        "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
        "        self.dec_blocks = nn.ModuleList([Block_de(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        for i in range(len(self.chs)-1):\n",
        "            x        = self.upconvs[i](x)\n",
        "            enc_ftrs = self.crop(encoder_features[i], x)\n",
        "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
        "            x        = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self, enc_ftrs, x):\n",
        "        _, _, H, W = x.shape\n",
        "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
        "        return enc_ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtWGMjxzwOje"
      },
      "source": [
        "class InvolutionUNet(nn.Module):\n",
        "    def __init__(self, enc_chs=(3,64,128,256,512), dec_chs=(512, 256, 128, 64), num_class=1, retain_dim=False, out_sz=(572,572)):\n",
        "        super().__init__()\n",
        "        self.encoder     = Encoder(enc_chs)\n",
        "        self.decoder     = Decoder(dec_chs)\n",
        "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
        "        self.retain_dim  = retain_dim\n",
        "        self.out_sz = out_sz\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_ftrs = self.encoder(x)\n",
        "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
        "        out      = self.head(out)\n",
        "        if self.retain_dim:\n",
        "            out = F.interpolate(out, self.out_sz)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGnvQx1YEnmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRE-QnDEnsY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rojx6_YuyDOF"
      },
      "source": [
        "## Inference on the Best Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe866jTQEnvD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR8T033Dz3nz"
      },
      "source": [
        "test_transform = A.Compose(\n",
        "    [\n",
        "        #A.CenterCrop(height=224, width=224),\n",
        "        A.Resize(height=720, width=720),\n",
        "        A.Normalize(mean=(0.64, 0.6, 0.58),std=(0.14,0.15, 0.152)),\n",
        "        ToTensor(),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLvHdVcU-xJ3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysgupjbyEnxj",
        "outputId": "2eaae394-12d4-499c-97f6-bb2b1c405b22"
      },
      "source": [
        "best_model = InvolutionUNet(enc_chs=(3,64,128,256), dec_chs=(256, 128, 64), num_class=3, retain_dim=False, out_sz=(128,128))\n",
        "\n",
        "best_ckp = torch.load('/content/drive/MyDrive/CV_Project/CheckPoints/r3/unet-14.pt')\n",
        "\n",
        "best_model.load_state_dict(best_ckp['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InjHsUNxP5-W",
        "outputId": "cb085c59-2203-4304-bdfe-0edf39b9f869"
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Jun  1 13:40 sample_data\n",
            "drwx------ 6 root root 4096 Jun 13 07:43 drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oouH-7tNSsh8",
        "outputId": "c43639ba-17f9-4525-a872-7d39c73efb60"
      },
      "source": [
        "'''\n",
        "image_hazy_path = '/content/kate-joie-a8zRxmKSnJ4-unsplash.jpg'\n",
        "hazy = cv2.imread(image_hazy_path)\n",
        "hazy = cv2.cvtColor(hazy, cv2.COLOR_BGR2RGB)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimage_hazy_path = '/content/kate-joie-a8zRxmKSnJ4-unsplash.jpg'\\nhazy = cv2.imread(image_hazy_path)\\nhazy = cv2.cvtColor(hazy, cv2.COLOR_BGR2RGB)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K0odMtRmU_PH",
        "outputId": "b683bc5c-c2f5-4177-ef7f-41fb49021e1f"
      },
      "source": [
        "'''\n",
        "plt.imshow(hazy)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nplt.imshow(hazy)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqYdBIQ3P6BG"
      },
      "source": [
        "def dehaze_image(hazy_image, model, transform):\n",
        "  mask_dummy = np.zeros_like(hazy_image)\n",
        "  transformed = transform(image=hazy_image, mask=mask_dummy)\n",
        "  #hazy = cv2.imread(image_hazy_path)\n",
        "  #hazy = cv2.cvtColor(hazy, cv2.COLOR_BGR2RGB)\n",
        "  hazy_image_transformed = transformed['image']\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    hazy_image_tensor = torch.tensor(hazy_image_transformed).to(device).unsqueeze(0)\n",
        "    model = model.to(device)\n",
        "    #print(hazy_image.shape)\n",
        "    pred_mask_tensor = model(hazy_image_tensor)\n",
        "    #print(pred_mask_tensor.shape)\n",
        "    pred_mask_tensor_final = torch.reshape(pred_mask_tensor, hazy_image_tensor.shape)\n",
        "    #print(pred_mask_tensor_final.shape)\n",
        "        #maxValue = np.amax(pred_masks_fod.detach().cpu().numpy())\n",
        "        #minValue = np.amin(pred_masks_fod.detach().cpu().numpy())\n",
        "    \n",
        "    pred_mask = (np.clip(pred_mask_tensor_final.detach().cpu().squeeze(0).permute(1,2,0).numpy(), 0 , 1)*255).astype('uint8')\n",
        "    #print(pred_mask.shape)\n",
        "  return pred_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj27H9204k8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3249dbb7-3977-4e9b-90b3-c9168aded32d"
      },
      "source": [
        "'''\n",
        "dehazed = dehaze_image(hazy, best_model, test_transform)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndehazed = dehaze_image(hazy, best_model, test_transform)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuSd-C7yA4X8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16b66c4d-0bce-4f50-deaa-87447780c650"
      },
      "source": [
        "'''\n",
        "plt.imshow(dehazed)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nplt.imshow(dehazed)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LopWsDDJV4LM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "9aY4RE7DWy4c",
        "outputId": "0f07b83c-19a1-4dab-e13a-17ea39d47108"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "Dehazer = lambda hazy : dehaze_image(hazy, best_model, test_transform)\n",
        "\n",
        "iface = gr.Interface(fn=Dehazer, \n",
        "                     inputs= gr.inputs.Image(label = 'Hazy Image'),\n",
        "                     outputs = gr.outputs.Image(label = 'Dehazed Image'),\n",
        "                     live = True,\n",
        "                     title = \"Efface the haze - Demo\",\n",
        "                     #description = 'This application removes haze and generates a clear picture',\n",
        "                     allow_flagging = False,\n",
        "                     )\n",
        "iface.launch(share=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://31565.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://31565.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f1bf3ef2890>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://31565.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Myuw4yYCBp",
        "outputId": "45807576-e583-42f0-b10a-c2b08a258dce"
      },
      "source": [
        "print(\"Notebook running\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Notebook running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaV_1LUklJff"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}